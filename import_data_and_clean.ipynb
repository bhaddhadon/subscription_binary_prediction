{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import isnan, when, count, col, lit, udf\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re\n",
    "import scipy.stats as stats\n",
    "from itertools import combinations\n",
    "\n",
    "spark = SparkSession.builder.appName(\"CSVLoad\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Schema of data and read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_schema_expression(path,delim=',',samp_nrows=100):\n",
    "    int_types = [np.int64,int]\n",
    "    float_types = [np.float64,float]\n",
    "\n",
    "    df = pd.read_csv(path,delimiter=delim,nrows=samp_nrows)\n",
    "    cols_og = [i for i in df.columns.values]\n",
    "    cols_edited = [re.sub('[^a-zA-Z0-9_.]', '',i).replace('.','_') for i in cols_og]\n",
    "\n",
    "    schema_list = []\n",
    "    col_list = []\n",
    "    for col in cols_og:\n",
    "        if df[col].dtype in int_types:\n",
    "            schema_str = str(col)+' int'\n",
    "        elif df[col].dtype in float_types:\n",
    "            schema_str = str(col)+' double'\n",
    "        else:\n",
    "            schema_str = str(col)+' string'\n",
    "        col_str = str(col) +' as '+re.sub('[^a-zA-Z0-9_.]', '',col).replace('.','_') \n",
    "        schema_list.append(schema_str)\n",
    "        col_list.append(col_str)\n",
    "    schema_statement = ','.join(schema_list)\n",
    "    col_convert_dict = dict(list(zip(cols_og,cols_edited)))\n",
    "\n",
    "    return col_convert_dict,schema_statement\n",
    "\n",
    "cols_dict,schema = format_schema_expression('bank-additional-full.csv',delim=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': 'age', 'job': 'job', 'marital': 'marital', 'education': 'education', 'default': 'default', 'housing': 'housing', 'loan': 'loan', 'contact': 'contact', 'month': 'month', 'day_of_week': 'day_of_week', 'duration': 'duration', 'campaign': 'campaign', 'pdays': 'pdays', 'previous': 'previous', 'poutcome': 'poutcome', 'emp.var.rate': 'emp_var_rate', 'cons.price.idx': 'cons_price_idx', 'cons.conf.idx': 'cons_conf_idx', 'euribor3m': 'euribor3m', 'nr.employed': 'nr_employed', 'y': 'y'}\n"
     ]
    }
   ],
   "source": [
    "print(cols_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "df_bank_full=spark.read.csv('bank-additional-full.csv',\n",
    "                            sep = ';',\n",
    "                            header=True,\n",
    "                            inferSchema=True)\n",
    "for key,val in cols_dict.items():\n",
    "    df_bank_full = df_bank_full.withColumnRenamed(key,val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- loan: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- month: string (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- pdays: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- emp_var_rate: double (nullable = true)\n",
      " |-- cons_price_idx: double (nullable = true)\n",
      " |-- cons_conf_idx: double (nullable = true)\n",
      " |-- euribor3m: double (nullable = true)\n",
      " |-- nr_employed: double (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_bank_full.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_rows:41188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+----------+\n",
      "|  y|count|percentage|\n",
      "+---+-----+----------+\n",
      "| no|36548|      89.0|\n",
      "|yes| 4640|      11.0|\n",
      "+---+-----+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "## 1) row count: 41188\n",
    "\n",
    "total_rows = df_bank_full.count()\n",
    "print(f\"total_rows:{total_rows}\")\n",
    "\n",
    "## 2) check null values: no rows with null values\n",
    "# |age|job|marital|education|default|housing|loan|contact|month|day_of_week|duration|campaign|pdays|previous|poutcome|emp_var_rate|cons_price_idx|cons_conf_idx|euribor3m|nr_employed|  y|\n",
    "# +---+---+-------+---------+-------+-------+----+-------+-----+-----------+--------+--------+-----+--------+--------+------------+--------------+-------------+---------+-----------+---+\n",
    "# |  0|  0|      0|        0|      0|      0|   0|      0|    0|          0|       0|       0|    0|       0|       0|           0|             0|            0|        0|          0|  0|\n",
    "# +---+---+-------+---------+-------+-------+----+-------+-----+-----------+--------+--------+-----+--------+--------+------------+--------------+-------------+---------+-----------+---+\n",
    "df_bank_full.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_bank_full.columns]).show()\n",
    "\n",
    "\n",
    "## 3) check continuous variables\n",
    "df_bank_full\\\n",
    "    .select(F.percentile_approx('nr_employed', [0.0,0.01,0.05,0.1,0.25, 0.5, 0.75,0.9,0.95,0.99,1.0], 1000000).alias('quantiles')).collect()[0].quantiles\n",
    "#----------------------------------------------------------------------------------\n",
    "# percentile [0,1,5,10,25,50,75,90,95,99,100]\n",
    "#\n",
    "# A. customer demographics\n",
    "# age: [17, 23, 26, 28, 32, 38, 47, 55, 58, 71, 98]\n",
    "#\n",
    "# B. behavioral history prior to this campaign\n",
    "# pdays: [0, 3, 999, 999, 999, 999, 999, 999, 999, 999, 999]\n",
    "# previous: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 7]\n",
    "#\n",
    "# C. respose to this campaign\n",
    "# duration: [0, 11, 36, 59, 102, 180, 319, 551, 753, 1272, 4918]\n",
    "# campaign: [1, 1, 1, 1, 1, 2, 3, 5, 7, 14, 56]\n",
    "#\n",
    "# D. economics indicators\n",
    "# emp_var_rate: [-3.4, -3.4, -2.9, -1.8, -1.8, 1.1, 1.4, 1.4, 1.4, 1.4, 1.4]\n",
    "# cons_price_idx: [92.201,92.201,92.713,92.893,93.075,93.749,93.994,94.465,94.465,94.465,94.767]\n",
    "# cons_conf_idx: [-50.8, -49.5, -47.1, -46.2, -42.7, -41.8, -36.4, -36.1, -33.6, -26.9, -26.9]\n",
    "# euribor3m: [0.634, 0.655, 0.797, 1.046, 1.344, 4.857, 4.961, 4.964, 4.966, 4.968, 5.045]\n",
    "# nr_employed: [4963.6,4963.6,5017.5,5076.2,5099.1,5191.0,5228.1,5228.1,5228.1,5228.1,5228.1]\n",
    "#\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "## 4) check discreet/categorical variations\n",
    "df_bank_full.groupBy('y').count()\\\n",
    "        .withColumn('percentage',F.round(F.round(col('count')/total_rows,2)*100,2))\\\n",
    "            .sort(F.desc('percentage')).show()\n",
    "#\n",
    "# A. customer demographics\n",
    "# job\n",
    "# +-------------+-----+----------+\n",
    "# |          job|count|percentage|\n",
    "# +-------------+-----+----------+\n",
    "# |       admin.|10422|      25.0|\n",
    "# |  blue-collar| 9254|      22.0|\n",
    "# |   technician| 6743|      16.0|\n",
    "# |     services| 3969|      10.0|\n",
    "# |   management| 2924|       7.0|\n",
    "# |      retired| 1720|       4.0|\n",
    "# | entrepreneur| 1456|       4.0|\n",
    "# |self-employed| 1421|       3.0|\n",
    "# |    housemaid| 1060|       3.0|\n",
    "# |      student|  875|       2.0|\n",
    "# |   unemployed| 1014|       2.0|\n",
    "# |      unknown|  330|       1.0|\n",
    "# +-------------+-----+----------+\n",
    "#\n",
    "# marital\n",
    "# +--------+-----+----------+\n",
    "# | marital|count|percentage|\n",
    "# +--------+-----+----------+\n",
    "# | married|24928|      61.0|\n",
    "# |  single|11568|      28.0|\n",
    "# |divorced| 4612|      11.0|\n",
    "# | unknown|   80|       0.0|\n",
    "# +--------+-----+----------+\n",
    "#\n",
    "# education\n",
    "# +-------------------+-----+----------+\n",
    "# |          education|count|percentage|\n",
    "# +-------------------+-----+----------+\n",
    "# |  university.degree|12168|      30.0|\n",
    "# |        high.school| 9515|      23.0|\n",
    "# |           basic.9y| 6045|      15.0|\n",
    "# |professional.course| 5243|      13.0|\n",
    "# |           basic.4y| 4176|      10.0|\n",
    "# |           basic.6y| 2292|       6.0|\n",
    "# |            unknown| 1731|       4.0|\n",
    "# |         illiterate|   18|       0.0|\n",
    "# +-------------------+-----+----------+\n",
    "\n",
    "# B. behavioral history prior to this campaign\n",
    "# default\n",
    "# +-------+-----+----------+\n",
    "# |default|count|percentage|\n",
    "# +-------+-----+----------+\n",
    "# |     no|32588|      79.0|\n",
    "# |unknown| 8597|      21.0|\n",
    "# |    yes|    3|       0.0|\n",
    "# +-------+-----+----------+\n",
    "#\n",
    "# housing\n",
    "# +-------+-----+----------+\n",
    "# |housing|count|percentage|\n",
    "# +-------+-----+----------+\n",
    "# |    yes|21576|      52.0|\n",
    "# |     no|18622|      45.0|\n",
    "# |unknown|  990|       2.0|\n",
    "# +-------+-----+----------+\n",
    "#\n",
    "# loan\n",
    "# +-------+-----+----------+\n",
    "# |   loan|count|percentage|\n",
    "# +-------+-----+----------+\n",
    "# |     no|33950|      82.0|\n",
    "# |    yes| 6248|      15.0|\n",
    "# |unknown|  990|       2.0|\n",
    "# +-------+-----+----------+\n",
    "#\n",
    "# contact\n",
    "# +---------+-----+----------+\n",
    "# |  contact|count|percentage|\n",
    "# +---------+-----+----------+\n",
    "# | cellular|26144|      63.0|\n",
    "# |telephone|15044|      37.0|\n",
    "# +---------+-----+----------+\n",
    "#\n",
    "# month \n",
    "# +-----+-----+----------+\n",
    "# |month|count|percentage|\n",
    "# +-----+-----+----------+\n",
    "# |  may|13769|      33.0|\n",
    "# |  jul| 7174|      17.0|\n",
    "# |  aug| 6178|      15.0|\n",
    "# |  jun| 5318|      13.0|\n",
    "# |  nov| 4101|      10.0|\n",
    "# |  apr| 2632|       6.0|\n",
    "# |  oct|  718|       2.0|\n",
    "# |  mar|  546|       1.0|\n",
    "# |  sep|  570|       1.0|\n",
    "# |  dec|  182|       0.0|\n",
    "# +-----+-----+----------+\n",
    "#\n",
    "# day_of_week\n",
    "# +-----------+-----+----------+\n",
    "# |day_of_week|count|percentage|\n",
    "# +-----------+-----+----------+\n",
    "# |        mon| 8514|      21.0|\n",
    "# |        thu| 8623|      21.0|\n",
    "# |        tue| 8090|      20.0|\n",
    "# |        wed| 8134|      20.0|\n",
    "# |        fri| 7827|      19.0|\n",
    "# +-----------+-----+----------+\n",
    "#\n",
    "# poutcome\n",
    "# +-----------+-----+----------+\n",
    "# |   poutcome|count|percentage|\n",
    "# +-----------+-----+----------+\n",
    "# |nonexistent|35563|      86.0|\n",
    "# |    failure| 4252|      10.0|\n",
    "# |    success| 1373|       3.0|\n",
    "# +-----------+-----+----------+\n",
    "#\n",
    "# C. respose to this campaign\n",
    "# y\n",
    "# +---+-----+----------+\n",
    "# |  y|count|percentage|\n",
    "# +---+-----+----------+\n",
    "# | no|36548|      89.0|\n",
    "# |yes| 4640|      11.0|\n",
    "# +---+-----+----------+\n",
    "\n",
    "#----------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleansing and Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## continuous variables\n",
    "#----------------------------------------------------------------------------------\n",
    "# pdays: [0, 3, 999, 999, 999, 999, 999, 999, 999, 999, 999] ->\n",
    "# valid 'pdays' recency represent less than 5%, hence not mneaningful. Can use 'previous' instead\n",
    "# previous: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 7]\n",
    "\n",
    "def imputePrevious(x):\n",
    "    '''\n",
    "    return 0 for missing data\n",
    "    csp max at 5\n",
    "    '''\n",
    "    if x == None:\n",
    "        return 0\n",
    "    elif x<=5:\n",
    "        return x\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "impute_previous = udf(imputePrevious,IntegerType())\n",
    "\n",
    "# C. respose to this campaign\n",
    "# duration: [0, 11, 36, 59, 102, 180, 319, 551, 753, 1272, 4918] ->\n",
    "# cannot be known prior to this campaign, hence need to drop\n",
    "#\n",
    "# campaign: [1, 1, 1, 1, 1, 2, 3, 5, 7, 14, 56] -> substract 1 (this campaign attempt)\n",
    "#\n",
    "def imputeCampaign(x):\n",
    "    '''\n",
    "    subtract this campaign's attempt (assume 1 attempt)\n",
    "    return 0 for missing data\n",
    "    csp max at 15\n",
    "    '''\n",
    "    if x == None:\n",
    "        return 0\n",
    "    elif x-1<=15:\n",
    "        return x-1\n",
    "    else:\n",
    "        return 15\n",
    "\n",
    "impute_campaign = udf(imputeCampaign,IntegerType())\n",
    "\n",
    "#----------------------------------------------------------------------------------\n",
    "\n",
    "df_bank_impute = df_bank_full.withColumn('previous',impute_previous(col('previous')))\\\n",
    "    .withColumn('campaign',impute_campaign(col('campaign')))\\\n",
    "        .drop('pdays','duration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>basic.4y</th>\n",
       "      <td>3967</td>\n",
       "      <td>484</td>\n",
       "      <td>4451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic.6y</th>\n",
       "      <td>2104</td>\n",
       "      <td>188</td>\n",
       "      <td>2292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>basic.9y</th>\n",
       "      <td>5999</td>\n",
       "      <td>496</td>\n",
       "      <td>6495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high.school</th>\n",
       "      <td>8724</td>\n",
       "      <td>1109</td>\n",
       "      <td>9833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>illiterate</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professional.course</th>\n",
       "      <td>4835</td>\n",
       "      <td>620</td>\n",
       "      <td>5455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>university.degree</th>\n",
       "      <td>10905</td>\n",
       "      <td>1739</td>\n",
       "      <td>12644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>36548</td>\n",
       "      <td>4640</td>\n",
       "      <td>41188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y                       no   yes  total\n",
       "education                              \n",
       "basic.4y              3967   484   4451\n",
       "basic.6y              2104   188   2292\n",
       "basic.9y              5999   496   6495\n",
       "high.school           8724  1109   9833\n",
       "illiterate              14     4     18\n",
       "professional.course   4835   620   5455\n",
       "university.degree    10905  1739  12644\n",
       "total                36548  4640  41188"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## impute education variables by mode of each age_job cohort\n",
    "#\n",
    "#\n",
    "# df = df_bank_impute.select('education','y').toPandas()\n",
    "# data_crosstab = pd.crosstab(df['education'],\n",
    "#                             df['y'],\n",
    "#                            margins=True, margins_name='total')\n",
    "# data_crosstab\n",
    "\n",
    "# y\tno\tyes\ttotal\n",
    "# unknown\t1480\t251\t1731\n",
    "# total\t36548\t4640\t41188\n",
    "# cannot drop 'unknown' as % yes case are high in this category\n",
    "# try using age_job to impute\n",
    "\n",
    "def ageGroup(x):\n",
    "    ''' \n",
    "    bin age into broad group\n",
    "    a.student_age : <23\n",
    "    b.working_age : 23-60\n",
    "    c.retired_age : >60\n",
    "    if missing then impute with working_age\n",
    "    '''\n",
    "    if x == None:\n",
    "        return 'b.working_age'\n",
    "    elif x<23:\n",
    "        return 'a.student_age'\n",
    "    elif x<=60:\n",
    "        return 'b.working_age'\n",
    "    else:\n",
    "        return 'c.retired_age'\n",
    "\n",
    "age_group = udf(ageGroup,StringType())\n",
    "age_job = udf(lambda x: x[0]+'_'+x[1],StringType())\n",
    "\n",
    "df_bank_impute = df_bank_impute\\\n",
    "    .withColumn('age_job',age_job(F.array(age_group(col('age')),col('job'))))\n",
    "\n",
    "total_valid_edu = df_bank_impute.filter(col('education')!='unknown').count()\n",
    "\n",
    "edu_impute_dict =df_bank_impute.filter(col('education')!='unknown')\\\n",
    "        .select('age_job','education')\\\n",
    "            .groupBy('age_job','education').count()\\\n",
    "                .withColumn('percentage',F.round(F.round(col('count')/total_valid_edu,4)*100,2))\\\n",
    "                    .sort(F.asc('age_job'),F.desc('percentage')).toPandas()\\\n",
    "                        .drop_duplicates(subset='age_job',keep='first')\\\n",
    "                            .set_index('age_job').to_dict()['education']\n",
    "\n",
    "impute_edu = udf(lambda x: edu_impute_dict[x[1]] if ((x[0]=='unknown') and\n",
    " (x[1] in edu_impute_dict.keys())) else x[0],StringType())\n",
    "\n",
    "df_bank_impute = df_bank_impute\\\n",
    "    .withColumn('education',impute_edu(F.array(col('education'),col('age_job'))))\n",
    "\n",
    "df = df_bank_impute.select('education','y').toPandas()\n",
    "data_crosstab = pd.crosstab(df['education'],\n",
    "                            df['y'],\n",
    "                           margins=True, margins_name='total')\n",
    "data_crosstab\n",
    "\n",
    "# y\tno\tyes\ttotal\n",
    "# education\t\t\t\n",
    "# basic.4y\t3967\t484\t4451\n",
    "# basic.6y\t2104\t188\t2292\n",
    "# basic.9y\t5999\t496\t6495\n",
    "# high.school\t8724\t1109\t9833\n",
    "# illiterate\t14\t4\t18\n",
    "# professional.course\t4835\t620\t5455\n",
    "# university.degree\t10905\t1739\t12644\n",
    "# total\t36548\t4640\t41188\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>admin.</th>\n",
       "      <td>9138</td>\n",
       "      <td>1365</td>\n",
       "      <td>10503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blue-collar</th>\n",
       "      <td>8819</td>\n",
       "      <td>653</td>\n",
       "      <td>9472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entrepreneur</th>\n",
       "      <td>1332</td>\n",
       "      <td>124</td>\n",
       "      <td>1456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housemaid</th>\n",
       "      <td>954</td>\n",
       "      <td>106</td>\n",
       "      <td>1060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>management</th>\n",
       "      <td>2596</td>\n",
       "      <td>328</td>\n",
       "      <td>2924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>retired</th>\n",
       "      <td>1299</td>\n",
       "      <td>442</td>\n",
       "      <td>1741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>self-employed</th>\n",
       "      <td>1272</td>\n",
       "      <td>149</td>\n",
       "      <td>1421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>services</th>\n",
       "      <td>3646</td>\n",
       "      <td>323</td>\n",
       "      <td>3969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>600</td>\n",
       "      <td>275</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technician</th>\n",
       "      <td>6022</td>\n",
       "      <td>731</td>\n",
       "      <td>6753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unemployed</th>\n",
       "      <td>870</td>\n",
       "      <td>144</td>\n",
       "      <td>1014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>36548</td>\n",
       "      <td>4640</td>\n",
       "      <td>41188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y                 no   yes  total\n",
       "job                              \n",
       "admin.          9138  1365  10503\n",
       "blue-collar     8819   653   9472\n",
       "entrepreneur    1332   124   1456\n",
       "housemaid        954   106   1060\n",
       "management      2596   328   2924\n",
       "retired         1299   442   1741\n",
       "self-employed   1272   149   1421\n",
       "services        3646   323   3969\n",
       "student          600   275    875\n",
       "technician      6022   731   6753\n",
       "unemployed       870   144   1014\n",
       "total          36548  4640  41188"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## impute job variables by mode of each age_edu cohort\n",
    "#\n",
    "# df = df_bank_impute.select('job','y').toPandas()\n",
    "# data_crosstab = pd.crosstab(df['job'],\n",
    "#                             df['y'],\n",
    "#                            margins=True, margins_name='total')\n",
    "# data_crosstab\n",
    "\n",
    "# y\tno\tyes\ttotal\n",
    "# unknown\t293\t37\t330\n",
    "# total\t36548\t4640\t41188\n",
    "# cannot drop 'unknown' as % yes case are high in this category\n",
    "# try using age_education to impute\n",
    "\n",
    "age_edu = udf(lambda x: x[0]+'_'+x[1],StringType())\n",
    "\n",
    "df_bank_impute = df_bank_impute\\\n",
    "    .withColumn('age_edu',age_job(F.array(age_group(col('age')),col('education'))))\n",
    "\n",
    "total_valid_job = df_bank_impute.filter(col('job')!='unknown').count()\n",
    "\n",
    "job_impute_dict =df_bank_impute.filter(col('job')!='unknown')\\\n",
    "        .select('age_edu','job')\\\n",
    "            .groupBy('age_edu','job').count()\\\n",
    "                .withColumn('percentage',F.round(F.round(col('count')/total_valid_job,4)*100,2))\\\n",
    "                    .sort(F.asc('age_edu'),F.desc('percentage')).toPandas()\\\n",
    "                        .drop_duplicates(subset='age_edu',keep='first')\\\n",
    "                            .set_index('age_edu').to_dict()['job']\n",
    "\n",
    "impute_job = udf(lambda x: job_impute_dict[x[1]] if ((x[0]=='unknown') and\n",
    " (x[1] in job_impute_dict.keys())) else x[0],StringType())\n",
    "\n",
    "df_bank_impute = df_bank_impute\\\n",
    "    .withColumn('job',impute_job(F.array(col('job'),col('age_edu'))))\n",
    "\n",
    "df = df_bank_impute.select('job','y').toPandas()\n",
    "data_crosstab = pd.crosstab(df['job'],\n",
    "                            df['y'],\n",
    "                           margins=True, margins_name='total')\n",
    "data_crosstab\n",
    "\n",
    "# y\tno\tyes\ttotal\n",
    "# job\t\t\t\n",
    "# admin.\t9138\t1365\t10503\n",
    "# blue-collar\t8819\t653\t9472\n",
    "# entrepreneur\t1332\t124\t1456\n",
    "# housemaid\t954\t106\t1060\n",
    "# management\t2596\t328\t2924\n",
    "# retired\t1299\t442\t1741\n",
    "# self-employed\t1272\t149\t1421\n",
    "# services\t3646\t323\t3969\n",
    "# student\t600\t275\t875\n",
    "# technician\t6022\t731\t6753\n",
    "# unemployed\t870\t144\t1014\n",
    "# total\t36548\t4640\t41188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>divorced</th>\n",
       "      <td>4136</td>\n",
       "      <td>476</td>\n",
       "      <td>4612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>married</th>\n",
       "      <td>22463</td>\n",
       "      <td>2544</td>\n",
       "      <td>25007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>single</th>\n",
       "      <td>9949</td>\n",
       "      <td>1620</td>\n",
       "      <td>11569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>36548</td>\n",
       "      <td>4640</td>\n",
       "      <td>41188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y            no   yes  total\n",
       "marital                     \n",
       "divorced   4136   476   4612\n",
       "married   22463  2544  25007\n",
       "single     9949  1620  11569\n",
       "total     36548  4640  41188"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## impute marital variables by mode of each age_job cohort\n",
    "#\n",
    "# df = df_bank_impute.select('marital','y').toPandas()\n",
    "# data_crosstab = pd.crosstab(df['marital'],\n",
    "#                             df['y'],\n",
    "#                            margins=True, margins_name='total')\n",
    "# data_crosstab\n",
    "\n",
    "# y\tno\tyes\ttotal\n",
    "# unknown\t1480\t251\t1731\n",
    "# total\t36548\t4640\t41188\n",
    "# cannot drop 'unknown' as % yes case are high in this category\n",
    "# try using age_job to impute\n",
    "\n",
    "total_valid_marital = df_bank_impute.filter(col('marital')!='unknown').count()\n",
    "\n",
    "marital_impute_dict =df_bank_impute.filter(col('marital')!='unknown')\\\n",
    "        .select('age_job','marital')\\\n",
    "            .groupBy('age_job','marital').count()\\\n",
    "                .withColumn('percentage',F.round(F.round(col('count')/total_valid_marital,4)*100,2))\\\n",
    "                    .sort(F.asc('age_job'),F.desc('percentage')).toPandas()\\\n",
    "                        .drop_duplicates(subset='age_job',keep='first')\\\n",
    "                            .set_index('age_job').to_dict()['marital']\n",
    "\n",
    "impute_marital = udf(lambda x: marital_impute_dict[x[1]] if ((x[0]=='unknown') and\n",
    " (x[1] in marital_impute_dict.keys())) else x[0],StringType())\n",
    "\n",
    "df_bank_impute = df_bank_impute\\\n",
    "    .withColumn('marital',impute_marital(F.array(col('marital'),col('age_job'))))\n",
    "\n",
    "df = df_bank_impute.select('marital','y').toPandas()\n",
    "data_crosstab = pd.crosstab(df['marital'],\n",
    "                            df['y'],\n",
    "                           margins=True, margins_name='total')\n",
    "data_crosstab\n",
    "\n",
    "# y\tno\tyes\ttotal\n",
    "# marital\t\t\t\n",
    "# divorced\t4136\t476\t4612\n",
    "# married\t22463\t2544\t25007\n",
    "# single\t9949\t1620\t11569\n",
    "# total\t36548\t4640\t41188\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y           no   yes  total\n",
      "housing                    \n",
      "no       16596  2026  18622\n",
      "yes      19069  2507  21576\n",
      "total    35665  4533  40198\n",
      "Approach 1: The p-value approach to hypothesis testing in the decision rule\n",
      "chisquare-score is: 5.467477030849473  and p value is: 3.957375316998579e-06\n",
      "Null Hypothesis is rejected.\n"
     ]
    }
   ],
   "source": [
    "### check'housing' chi-square\n",
    "\n",
    "## with 'unknown': \n",
    "# chisquare-score is: 5.684494866173687  and p value is: 0.00011457832210592933\n",
    "# Null Hypothesis is rejected.\n",
    "\n",
    "## without 'unknown': \n",
    "# chisquare-score is: 5.467477030849473  and p value is: 3.957375316998579e-06\n",
    "# Null Hypothesis is rejected.\n",
    "\n",
    "# Conclusion: Impute with best guess from each age_job cohort\n",
    "\n",
    "df = df_bank_impute\\\n",
    "    .filter(col('housing')!='unknown')\\\n",
    "        .select('housing','y').toPandas()\n",
    "        \n",
    "data_crosstab = pd.crosstab(df['housing'],\n",
    "                            df['y'],\n",
    "                           margins=True, margins_name='total')\n",
    "print(data_crosstab)\n",
    "\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Calcualtion of Chisquare test statistics\n",
    "chi_square = 0\n",
    "rows = df['housing'].unique()\n",
    "columns = df['y'].unique()\n",
    "for i in columns:\n",
    "    for j in rows:\n",
    "        O = data_crosstab[i][j]\n",
    "        E = round(data_crosstab[i]['total'] * data_crosstab['total'][j] / data_crosstab['total']['total'],4)\n",
    "        chi_square += (O-E)**2/E\n",
    "\n",
    "# The p-value approach\n",
    "print(\"Approach 1: The p-value approach to hypothesis testing in the decision rule\")\n",
    "p_value = 1 - stats.norm.cdf(chi_square, (len(rows)-1)*(len(columns)-1))\n",
    "conclusion = \"Failed to reject the null hypothesis.\"\n",
    "if p_value <= alpha:\n",
    "    conclusion = \"Null Hypothesis is rejected.\"\n",
    "        \n",
    "print(\"chisquare-score is:\", chi_square, \" and p value is:\", p_value)\n",
    "print(conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>y</th>\n",
       "      <th>no</th>\n",
       "      <th>yes</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>16596</td>\n",
       "      <td>2027</td>\n",
       "      <td>18623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>yes</th>\n",
       "      <td>19952</td>\n",
       "      <td>2613</td>\n",
       "      <td>22565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>36548</td>\n",
       "      <td>4640</td>\n",
       "      <td>41188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "y           no   yes  total\n",
       "housing                    \n",
       "no       16596  2027  18623\n",
       "yes      19952  2613  22565\n",
       "total    36548  4640  41188"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## impute housing variables by mode of each age_job cohort\n",
    "\n",
    "total_valid_housing = df_bank_impute.filter(col('housing')!='unknown').count()\n",
    "\n",
    "housing_impute_dict =df_bank_impute.filter(col('housing')!='unknown')\\\n",
    "        .select('age_job','housing')\\\n",
    "            .groupBy('age_job','housing').count()\\\n",
    "                .withColumn('percentage',F.round(F.round(col('count')/total_valid_housing,4)*100,2))\\\n",
    "                    .sort(F.asc('age_job'),F.desc('percentage')).toPandas()\\\n",
    "                        .drop_duplicates(subset='age_job',keep='first')\\\n",
    "                            .set_index('age_job').to_dict()['housing']\n",
    "\n",
    "impute_housing = udf(lambda x: housing_impute_dict[x[1]] if ((x[0]=='unknown') and\n",
    " (x[1] in housing_impute_dict.keys())) else x[0],StringType())\n",
    "\n",
    "df_bank_impute = df_bank_impute\\\n",
    "    .withColumn('housing',impute_housing(F.array(col('housing'),col('age_job'))))\n",
    "\n",
    "df = df_bank_impute.select('housing','y').toPandas()\n",
    "data_crosstab = pd.crosstab(df['housing'],\n",
    "                            df['y'],\n",
    "                           margins=True, margins_name='total')\n",
    "data_crosstab\n",
    "\n",
    "# y\tno\tyes\ttotal\n",
    "# housing\t\t\t\n",
    "# no\t16596\t2027\t18623\n",
    "# yes\t19952\t2613\t22565\n",
    "# total\t36548\t4640\t41188\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y         no   yes  total\n",
      "loan                     \n",
      "no     30100  3850  33950\n",
      "yes     5565   683   6248\n",
      "total  35665  4533  40198\n",
      "Approach 1: The p-value approach to hypothesis testing in the decision rule\n",
      "chisquare-score is: 0.8810165452595269  and p value is: 0.5473557680695367\n",
      "Failed to reject the null hypothesis.\n"
     ]
    }
   ],
   "source": [
    "### check'loan' chi-square\n",
    "\n",
    "## with 'unknown': \n",
    "# chisquare-score is: 1.0940276122309665  and p value is: 0.817524766180606\n",
    "# Failed to reject the null hypothesis.\n",
    "\n",
    "## without 'unknown': \n",
    "# chisquare-score is: 0.8810165452595269  and p value is: 0.5473557680695367\n",
    "# Failed to reject the null hypothesis.\n",
    "\n",
    "# Conclusion: no need to impute. Can drop this feature\n",
    "\n",
    "df = df_bank_impute\\\n",
    "    .filter(col('loan')!='unknown')\\\n",
    "        .select('loan','y').toPandas()\n",
    "    \n",
    "data_crosstab = pd.crosstab(df['loan'],\n",
    "                            df['y'],\n",
    "                           margins=True, margins_name='total')\n",
    "print(data_crosstab)\n",
    "\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Calcualtion of Chisquare test statistics\n",
    "chi_square = 0\n",
    "rows = df['loan'].unique()\n",
    "columns = df['y'].unique()\n",
    "for i in columns:\n",
    "    for j in rows:\n",
    "        O = data_crosstab[i][j]\n",
    "        E = round(data_crosstab[i]['total'] * data_crosstab['total'][j] / data_crosstab['total']['total'],4)\n",
    "        chi_square += (O-E)**2/E\n",
    "\n",
    "# The p-value approach\n",
    "print(\"Approach 1: The p-value approach to hypothesis testing in the decision rule\")\n",
    "p_value = 1 - stats.norm.cdf(chi_square, (len(rows)-1)*(len(columns)-1))\n",
    "conclusion = \"Failed to reject the null hypothesis.\"\n",
    "if p_value <= alpha:\n",
    "    conclusion = \"Null Hypothesis is rejected.\"\n",
    "        \n",
    "print(\"chisquare-score is:\", chi_square, \" and p value is:\", p_value)\n",
    "print(conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 'month' and 'day_of_week' has no meaningful implications as \n",
    "### they cannot lead to actionable insights\n",
    "### advices regarding which month of day_of_week to solicit product to customers\n",
    "### are not practical\n",
    "\n",
    "## drop 'loan','age_job','age_edu','month','day_of_week'\n",
    "\n",
    "df_bank_impute = df_bank_impute\\\n",
    "    .drop('loan','age_job','age_edu','month','day_of_week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put 'yes' default under 'unknown'\n",
    "# too small observations to have its own category\n",
    "# +-------+-----+----------+\n",
    "# |default|count|percentage|\n",
    "# +-------+-----+----------+\n",
    "# |     no|32588|      79.0|\n",
    "# |unknown| 8597|      21.0|\n",
    "# |    yes|    3|       0.0|\n",
    "# +-------+-----+----------+\n",
    "\n",
    "impute_default = udf(lambda x: 'unknown' if x=='yes' else x,StringType())\n",
    "\n",
    "df_bank_impute = df_bank_impute\\\n",
    "    .withColumn('default',impute_default(col('default')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y            no   yes  total\n",
      "poutcome                    \n",
      "failure   36069  3746  39815\n",
      "success     479   894   1373\n",
      "total     36548  4640  41188\n",
      "Approach 1: The p-value approach to hypothesis testing in the decision rule\n",
      "chisquare-score is: 4119.883422967389  and p value is: 0.0\n",
      "Null Hypothesis is rejected.\n"
     ]
    }
   ],
   "source": [
    "### check'poutcome' chi-square\n",
    "\n",
    "## with 'nonexistence': \n",
    "# chisquare-score is: 4230.523060237804  and p value is: 0.0\n",
    "# Null Hypothesis is rejected.\n",
    "\n",
    "## 'nonexistence' grouped to 'success': \n",
    "# chisquare-score is: 41.64765927513662  and p value is: 0.0\n",
    "# Null Hypothesis is rejected.\n",
    "\n",
    "## 'nonexistence' grouped to 'failure': \n",
    "# chisquare-score is: 4119.883422967389  and p value is: 0.0\n",
    "# Null Hypothesis is rejected.\n",
    "\n",
    "# Conclusion: no need to collapse variation. Current variation gives superior chi-square\n",
    "\n",
    "collapse = udf(lambda x: 'failure' if x=='nonexistent' else x, StringType())\n",
    "df = df_bank_impute\\\n",
    "    .withColumn('poutcome',collapse(col('poutcome')))\\\n",
    "        .select('poutcome','y').toPandas()\n",
    "    \n",
    "data_crosstab = pd.crosstab(df['poutcome'],\n",
    "                            df['y'],\n",
    "                           margins=True, margins_name='total')\n",
    "print(data_crosstab)\n",
    "\n",
    "# significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Calcualtion of Chisquare test statistics\n",
    "chi_square = 0\n",
    "rows = df['poutcome'].unique()\n",
    "columns = df['y'].unique()\n",
    "for i in columns:\n",
    "    for j in rows:\n",
    "        O = data_crosstab[i][j]\n",
    "        E = round(data_crosstab[i]['total'] * data_crosstab['total'][j] / data_crosstab['total']['total'],4)\n",
    "        chi_square += (O-E)**2/E\n",
    "\n",
    "# The p-value approach\n",
    "print(\"Approach 1: The p-value approach to hypothesis testing in the decision rule\")\n",
    "p_value = 1 - stats.norm.cdf(chi_square, (len(rows)-1)*(len(columns)-1))\n",
    "conclusion = \"Failed to reject the null hypothesis.\"\n",
    "if p_value <= alpha:\n",
    "    conclusion = \"Null Hypothesis is rejected.\"\n",
    "        \n",
    "print(\"chisquare-score is:\", chi_square, \" and p value is:\", p_value)\n",
    "print(conclusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlation: \n",
    "#### Drop >80% correlated features\n",
    "#### Keep ones with highest correlation to target variable\n",
    "#### In Tree-based ensemble, we can keep correlated features but let's drop it here, \n",
    "#### giving options to use LogisticRegression or other formula-based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feats_to_compare: ['emp_var_rate', 'euribor3m', 'nr_employed']\n",
      "winning_feats:['nr_employed']\n",
      "cols_to_drop:['emp_var_rate', 'euribor3m']\n",
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- job: string (nullable = true)\n",
      " |-- marital: string (nullable = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- default: string (nullable = true)\n",
      " |-- housing: string (nullable = true)\n",
      " |-- contact: string (nullable = true)\n",
      " |-- campaign: integer (nullable = true)\n",
      " |-- previous: integer (nullable = true)\n",
      " |-- poutcome: string (nullable = true)\n",
      " |-- cons_price_idx: double (nullable = true)\n",
      " |-- cons_conf_idx: double (nullable = true)\n",
      " |-- nr_employed: double (nullable = true)\n",
      " |-- y: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# previous: [0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 7]\n",
    "#\n",
    "# C. respose to this campaign\n",
    "# duration: [0, 11, 36, 59, 102, 180, 319, 551, 753, 1272, 4918]\n",
    "# campaign: [1, 1, 1, 1, 1, 2, 3, 5, 7, 14, 56]\n",
    "#\n",
    "# D. economics indicators\n",
    "# emp_var_rate: [-3.4, -3.4, -2.9, -1.8, -1.8, 1.1, 1.4, 1.4, 1.4, 1.4, 1.4]\n",
    "# cons_price_idx: [92.201,92.201,92.713,92.893,93.075,93.749,93.994,94.465,94.465,94.465,94.767]\n",
    "# cons_conf_idx: [-50.8, -49.5, -47.1, -46.2, -42.7, -41.8, -36.4, -36.1, -33.6, -26.9, -26.9]\n",
    "# euribor3m: [0.634, 0.655, 0.797, 1.046, 1.344, 4.857, 4.961, 4.964, 4.966, 4.968, 5.045]\n",
    "# nr_employed: [4963.6,4963.6,5017.5,5076.2,5099.1,5191.0,5228.1,5228.1,5228.1,5228.1,5228.1]\n",
    "#\n",
    "continuous_feats_list = ['previous','campaign','emp_var_rate','cons_price_idx',\n",
    "                         'cons_conf_idx','euribor3m','nr_employed']\n",
    "\n",
    "combo = list(combinations(continuous_feats_list,2))\n",
    "target_combo = [(i,'y_int') for i in continuous_feats_list]\n",
    "combined_combo = combo+target_combo\n",
    "\n",
    "def get_corr(df_pyspark,combo,threshold=0.7):\n",
    "    '''get correlation of all pairs'''\n",
    "    y_int_func = udf(lambda x: 1 if x=='yes' else 0,IntegerType())\n",
    "    df = df_pyspark.withColumn('y_int',y_int_func(col('y'))).toPandas()\n",
    "\n",
    "    df_corr = pd.DataFrame(columns=['col1','col2','corr','abs_corr','to_compare'])\n",
    "    for idx,(i,j) in enumerate(combo):\n",
    "        if abs(np.corrcoef(df[i], df[j])[0, 1]) > threshold:\n",
    "            to_compare = 1\n",
    "        else:\n",
    "            to_compare = 0\n",
    "        df_corr.loc[idx] = [i,j,np.corrcoef(df[i], df[j])[0, 1],abs(np.corrcoef(df[i], df[j])[0, 1]),to_compare]\n",
    "\n",
    "    return df_corr\n",
    "\n",
    "### Assign 80% threshold\n",
    "\n",
    "df_corr = get_corr(df_bank_impute,combo=combined_combo,threshold=0.8)\n",
    "\n",
    "y_int_corr_dict = df_corr.iloc[np.where(df_corr['col2']=='y_int')][['col1','abs_corr']].set_index('col1').to_dict()['abs_corr']\n",
    "\n",
    "\n",
    "conds = (df_corr['to_compare']==1)\n",
    "df_corr_to_compare = df_corr.iloc[np.where(conds)]\n",
    "\n",
    "initial_feats_to_compare = [i for i in df_corr_to_compare['col1'].unique()] +\\\n",
    "    [i for i in df_corr_to_compare['col2'].unique() if i not in df_corr_to_compare['col1'].unique()]\n",
    "feats_to_compare = initial_feats_to_compare\n",
    "latest_rows_to_compare = int(df_corr_to_compare.shape[0])\n",
    "rows_to_compare = latest_rows_to_compare-1\n",
    "while rows_to_compare < latest_rows_to_compare:\n",
    "    latest_rows_to_compare = rows_to_compare\n",
    "    print(f\"feats_to_compare: {feats_to_compare}\")\n",
    "    conds_compare = (df_corr_to_compare['col1'].isin(feats_to_compare))|(df_corr_to_compare['col2'].isin(feats_to_compare))\n",
    "    df_compare = df_corr_to_compare.iloc[np.where(conds_compare)]\n",
    "    df_compare['winning_feat'] = df_compare.apply(lambda row: row['col1'] if y_int_corr_dict[row['col1']]>y_int_corr_dict[row['col2']] else row['col2'],axis=1)\n",
    "    feats_to_compare = [i for i in df_compare['winning_feat'].unique()]\n",
    "    rows_to_compare = int(df_corr_to_compare.iloc[np.where(conds_compare)].shape[0])\n",
    "\n",
    "final_conds = (df_compare['col1'].isin(feats_to_compare))&(df_compare['col2'].isin(feats_to_compare))\n",
    "winning_feats  = [i for i in df_compare.iloc[np.where(final_conds)]['winning_feat'].unique()]\n",
    "cols_to_drop = [i for i in initial_feats_to_compare if i not in winning_feats]\n",
    "print(f\"winning_feats:{winning_feats}\")\n",
    "print(f\"cols_to_drop:{cols_to_drop}\")\n",
    "\n",
    "\n",
    "### Drop correlated vars\n",
    "\n",
    "df_bank_impute = df_bank_impute.drop(*cols_to_drop)\n",
    "df_bank_impute.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "\n",
    "df_bank_impute.write.format('parquet').saveAsTable('bank_impute_clean')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06a6aaded2eddfacce48838df1eb48db94706e28754b48676ed0de5791f50a44"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('py39': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
